
Title:  Practical Machine Learning -- Course Project

Author: J. Conklin

Prediction Models for Quantitaive Self Movement Data

The goal of this project is to take a training set of 19,622
observations and 160 variables to build a prediction model
for the manner of performing an exercise in a test set of
twenty cases.

Four models were tested: CART, LDA, Support Vector Machines, and
Random Forest.  Two fold CV was iterated 25 times to build a vector
of the accuracy measures for each iteration.  The R reported accuracy
(correct classification percentage) is the measure of the out of sample
error for this project.

The highest accuracy was obtained with a Random Forest Model, averaging
a correct classification rate of 96.5%  The 160 variables were reduced
as follows:

1.  Seven time and user ID related variables were set aside
    in the training and testing data sets.

2.  Variables with more than 1/3 missing cases were set aside;
    they were considered too have too many missing values for
    imputation to work well.

3.  Integer and numeric variables were retained.

4.  Factor variables in the training and testing data sets
    with at least ten unique levels that could be converted to 
    numeric were converted and retained.   Those with fewer than 
    ten unique values were set aside.  It was assumed at least ten
    unique values was sufficient to reasonably approximate a 
    continuous variable.
    
5.  Principal components was applied to the remaining variables
    to reduce the dimensionality of the predictors to a more
    manageable number.  The first 21 principal components for
    building the prediction model was the result of these steps.
    
The testing data set predictions from the four models are given
at the end of the program.

```{r}

# Open required libraries 

  library(caret)

  library(e1071)
 
```

```{r}

# Download and read in training data set 

  url <- "https://d396qusza40orc.cloudfront.net/predmachlearn/pml-training.csv"

  destfile <- "pml-training.csv"

  download.file(url,destfile)

  training = read.csv(destfile)
 
```

```{r}

# Download and read in testing data set 

  url <- "https://d396qusza40orc.cloudfront.net/predmachlearn/pml-testing.csv"

  destfile <- "pml-testing.csv"

  download.file(url,destfile)

  testing = read.csv(destfile)

# Remove R objects no longer needed

  rm(url,destfile)
 
```

```{r}

# Remove user names and file date and time data variables from data sets

  training <- training[,-c(1:7)]

  testing <- testing[,-c(1:7)]
 
```

```{r}

# Identify variables in training data set except for 
# response variable that are more than 1/3 missing

  too_many_missing <- NULL

  for(i in 1:length(colnames(training))){

# Capture column indexes for variables that are all missing
  
    if(all(is.na(training[,i]))){
    
      too_many_missing <- c(too_many_missing,i)
    
    }

# Capture column indexes for variables that are more than 1/3 missing

    if(length(table(is.na(training[,i]))) > 1){
    
      if(table(is.na(training[,i]))[2]/length(is.na(training[,i]) > 1/3)){
      
        too_many_missing <- c(too_many_missing,i)
      
      }
    
    }
  
}

# Remove variables from training and test data sets
# that are more than 1/3 missing in training data set

  if(length(too_many_missing) > 0){
  
    training <- training[,-c(too_many_missing)]
  
    testing <- testing[,-c(too_many_missing)]  
  
}

```

```{r}

# Identify variables in testing data set that are more than 1/3 missing

  too_many_missing <- NULL

  for(i in 1:length(colnames(testing))){

# Capture column indexes for variables that are all missing
  
    if(all(is.na(testing[,i]))){
    
      too_many_missing <- c(too_many_missing,i)
    
    }
    
# Capture column indexes for variables that are more than 1/3 missing

    if(length(table(is.na(testing[,i]))) > 1){
    
      if(table(is.na(testing[,i]))[2]/length(is.na(testing[,i]) > 1/3)){
      
        too_many_missing <- c(too_many_missing,i)
      
      }
    
    }
  
}

# Remove variables from training and test data sets
# that are more than 1/3 missing in testing data set

  if(length(too_many_missing) > 0){
  
    training <- training[,-c(too_many_missing)]
  
    testing <- testing[,-c(too_many_missing)]  
  
  }

# Remove R objects no longer needed

  rm(i,too_many_missing)

```

```{r}

# Examination of training data set suggests
# factor variables can be converted to numeric
# Convert to numeric except for response variable

  for(i in 1:(length(colnames(training))-1)){
  
    if(class(training[,i]) == "factor"){
    
      training[,i] <- as.numeric(training[,i])
    
    }
  
  }

```

```{r}

# Identify variables in training data set
# except for response variable that have
# fewer than ten unique values

  less_than_ten <- NULL

  for(i in 1:(length(colnames(training))-1)){
  
    if(length(table(training[,i])) < 10){
    
      less_than_ten <- c(less_than_ten,i)

    }
  
  }

# Remove variables in training and testing data sets
# except for response variable that have ten or fewer
# unique values in training data set

  if(length(less_than_ten) > 0){
  
    training <- training[,-c(less_than_ten)]
  
    testing <- testing[,-c(less_than_ten)]  
  
  }

```

```{r}

# Examination of testing data set suggests
# factor variables can be converted to numeric
# Convert to numeric

  for(i in 1:(length(colnames(testing))-1)){
  
    if(class(testing[,i]) == "factor"){
    
      testing[,i] <- as.numeric(testing[,i])
    
    }
  
  }

```

```{r}

# Identify variables in testing data set
# that have fewer than ten unique values

  less_than_ten <- NULL

  for(i in 1:(length(colnames(testing))-1)){
  
    if(length(table(testing[,i])) < 10){
    
      less_than_ten <- c(less_than_ten,i)
    
    }
  
  }

# Remove variables in training and testing data sets
# except for response variable that have ten or fewer
# unique values in testing data set

  if(length(less_than_ten) > 0){
  
    training <- training[,-c(less_than_ten)]
  
    testing <- testing[,-c(less_than_ten)]  
  
  }

# Remove R objects no longer needed

  rm(i,less_than_ten)

```

```{r}

# Remove last variable in testing data set as it
# is not a predictor

  testing <- testing[,-c(length(colnames(testing)))]

```

```{r}

# Preprocess first so that model is fit against 
# principal components of predictors

  preTrain <- preProcess(training[,-c(length(colnames(training)))],
                        method=c("pca","center","scale"),
                        thresh=0.95)

  trainPC <- predict(preTrain,training[,-c(length(colnames(training)))])

```

```{r}

# Preprocess testing data set to obtain principal 
# components of predictors for obtaining predictions
# on test data set with same number of principal 
# components as training data set

  preTest <- preProcess(testing,method=c("pca","center","scale"),
                        pcaComp=ncol(trainPC))

  testPC <- predict(preTest,testing)

# Synchronize preprocessed testing and training
# data sets so they have the same number of
# principal components

  if(ncol(trainPC) < ncol(testPC)){testPC <- testPC[,1:ncol(trainPC)]}
  if(ncol(testPC) < ncol(trainPC)){trainPC <- trainPC[,1:ncol(testPC)]}

```

```{r}

# Apply cross validation with two folds twenty-five
# times to build distribution of accuracy measure

  trainCtrl <- trainControl(method = "cv", number = 2)

```

```{r}

# Fit Classification and Regression Tree (CART) model
# to training data set and build up vector of accuracy
# measures

  rp_accuracy <- NULL

  for(i in 1:25){
 
    qsm_rp <- train(trainPC,training$classe, method = "rpart", 
                    trControl = trainCtrl)
  
    rp_accuracy <- c(rp_accuracy,max(qsm_rp$results[,2]))
  
  }

# Multiply CART accuracy by 100 to express as
# percentage

  rp_accuracy <- 100*(rp_accuracy)

```

```{r rp_accuracy, echo=FALSE}

# Construct histogram of CART accuracy measures

  hist(rp_accuracy,col="green",main="",xlab="",ylab="",
       xlim = c(min(rp_accuracy)-1,max(rp_accuracy)+1))

# Format histogram of CART accuracy measures

  title(main = "Accuracy over 25 Iterations of 2 Fold CV",col.main="blue")
  title(xlab = "Percent Accuracy of CART",col.lab="red",font.lab=2)
  title(ylab = "Frequency", font.lab=2)
  title(sub = "Figure 1 of 4",col.sub="red",font.sub=2)
  axis(1,font = 2)
  axis(2,font = 2)

# Remove R objects no longer needed

  rm(i,rp_accuracy)

```

```{r}

# Fit Linear Discriminat Analysis (LDA) model
# to training data set and build up vector of accuracy
# measures

  lda_accuracy <- NULL

  for(i in 1:25){
  
    qsm_lda <- train(trainPC,training$classe, method = "lda", 
                     trControl = trainCtrl)
  
    lda_accuracy <- c(lda_accuracy,max(qsm_lda$results[,2]))
  
  }

# Multiply LDA accuracy by 100 to express as
# percentage

  lda_accuracy <- 100*(lda_accuracy)

```

```{r lda_accuracy, echo=FALSE}

# Construct histogram of LDA accuracy measures

  hist(lda_accuracy,col="green",main="",xlab="",ylab="",
       xlim = c(min(lda_accuracy)-1,max(lda_accuracy)+1))

# Format histogram of LDA accuracy measures

  title(main = "Accuracy over 25 Iterations of 2 Fold CV",col.main="blue")
  title(xlab = "Percent Accuracy of LDA",col.lab="red",font.lab=2)
  title(ylab = "Frequency", font.lab=2)
  title(sub = "Figure 2 of 4",col.sub="red",font.sub=2)
  axis(1,font = 2)
  axis(2,font = 2)

# Remove R objects no longer needed

  rm(i,lda_accuracy)

```

```{r}

# Fit Support Vector Machine (SVM) model to training
# data set and build up vector of accuracy measures

  svm_accuracy <- NULL

  for(i in 1:25){
  
    qsm_svm <- train(trainPC,training$classe, method = "svmLinear2",
                     trControl = trainCtrl)
  
    svm_accuracy <- c(svm_accuracy,max(qsm_svm$results[,2]))
  
  }

# Multiply SVM accuracy by 100 to express as
# percentage

 svm_accuracy <- 100*(svm_accuracy)

```

```{r svm_accuracy, echo=FALSE}

# Construct histogram of SVM accuracy measures

  hist(svm_accuracy,col="green",main="",xlab="",ylab="",
       xlim = c(min(svm_accuracy)-1,max(svm_accuracy)+1))

# Format histogram of SVM accuracy measures

  title(main = "Accuracy over 25 Iterations of 2 Fold CV",col.main="blue")
  title(xlab = "Percent Accuracy of SVM",col.lab="red",font.lab=2)
  title(ylab = "Frequency", font.lab=2)
  title(sub = "Figure 3 of 4",col.sub="red",font.sub=2)
  axis(1,font = 2)
  axis(2,font = 2)

# Remove R objects no longer needed

  rm(i,svm_accuracy)

```

```{r}

# Fit Random Forest (RF) model to training data
# set and build up vector of accuracy measures

  rf_accuracy <- NULL

  for(i in 1:25){
  
    qsm_rf <- train(trainPC,training$classe, method = "rf", 
                    trControl = trainCtrl)
  
    rf_accuracy <- c(rf_accuracy,max(qsm_rf$results[,2]))
  
  }

# Multiply RF accuracy by 100 to express as
# percentage

  rf_accuracy <- 100*(rf_accuracy)

```

```{r rf_accuracy, echo=FALSE}

# Construct histogram of RF accuracy measures

  hist(rf_accuracy,col="green",main="",xlab="",ylab="",
       xlim = c(min(rf_accuracy)-1,max(rf_accuracy)+1))

# Format histogram of RF accuracy measures

  title(main = "Accuracy over 25 Iterations of 2 Fold CV",col.main="blue")
  title(xlab = "Percent Accuracy of RF",col.lab="red",font.lab=2)
  title(ylab = "Frequency", font.lab=2)
  title(sub = "Figure 4 of 4",col.sub="red",font.sub=2)
  axis(1,font = 2)
  axis(2,font = 2)

# Remove R objects no longer needed

  rm(i,rf_accuracy)


```

```{r}

# Compute predicted values for four models
# on testing set data

  qsm_rp_test  <- predict(qsm_rp,testPC)
  qsm_lda_test <- predict(qsm_lda,testPC)
  qsm_svm_test <- predict(qsm_svm,testPC)
  qsm_rf_test  <- predict(qsm_rf,testPC)

```

```{r}

# Print predictions from CART model

  qsm_rp_test  

# Print predictions from LDA model

  qsm_lda_test 
  
# Print predictions from SVM model
  
  qsm_svm_test 
  
# Print predictions from RF model
  
  qsm_rf_test  

```

```{r}

# Remove R objects no longer needed

rm(qsm_lda,qsm_rf,qsm_rp,qsm_svm)
rm(preTest,preTrain,testPC,trainPC,trainCtrl)
rm(qsm_rp_test,qsm_lda_test,qsm_svm_test,qsm_rf_test)

```
